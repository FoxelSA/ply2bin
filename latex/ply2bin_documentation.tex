\documentclass[a4paper, 11pt]{article}

%========================================================================
%
%       Packages inclusion
%
% =======================================================================

%\usepackage{../preambule}
\usepackage[latin1]{inputenc}
\usepackage[french]{babel}
\usepackage{amsmath}
%\usepackage{bbm}
\usepackage{lscape}
\usepackage{inputenc}
%\usepackage[refpage,french,noprefix]{nomencl}
\usepackage{lmodern}
\usepackage{url}
\usepackage{float, graphicx}
\usepackage[sectionbib]{chapterbib}

\author{ St\'ephane Flotron }
\title{\textbf{ply2bin documentation}}

% definition of useful command for the document
\renewcommand{\tilde}{\widetilde}
\renewcommand{\t}{\mathbf{t}}

%========================================================================
%
%       Document 
%
% =======================================================================
\begin{document}

   \maketitle
   
   \section*{Program description}
   
   The ply2bin software is a program which convert a point cloud in PLY file format into 
   a binary file readable for the DAV interface. 
   The keypoint of this sofware is to transform the (aligned) point cloud into the WebGL
   interface associated to the panorama.
   
   \section*{Mathematics}
   
   Suppose that we have an aligned point cloud in CH1903+ referential, and that we want to transform the points into
   the WebGL interface. In order to simplify the reading, let us introduce some notations. 
   
   \begin{table}[H]
      \begin{center}
        \begin{tabular}{|c|l|}
                \hline 
                    Notation & description \\
                \hline
                    $X_{CH1903}$ & 3D point in MN95 referential frame \\
                    $X_S$       & 3D point in shifted MN95 referential frame \\
                    $X_{omvg}$   & 3D point in openMVG referential frame \\
                    $X_{trans}$ & 3D point in rigidly transformed openMVG referential frame \\
                    $X_r$       & 3D point in pose referential frame \\
                    $X_c$       & 3D point in camera referential frame \\
                    $X_{pix}$   & 3D point in camera pixel coordinate frame \\
                \hline
        \end{tabular}
      \end{center}
      \label{3D point notation}
      \caption{Notions for 3D points in different referential frames}
   \end{table}
   
   The notation define above are strongly related to each other. Let $X_{CH1903}$ and $X_{trans}$ be the same
   3D point expressed in CH1903+ referential frame and in openMVG rigidly transformed referential frame. The relation 
   between these two points is given by:
   \begin{equation}
       X_{CH1903}  = s R_a ( X_{trans} - C_a ) + S \Leftrightarrow X_{trans} = \frac{1}{s} R_a^T ( X_{CH1903} -S ) + C_a
   \end{equation}
   where $s$ is the scale factor used to retrieve metric coordinates, $R_a$ is the rotation matrix used to align
   point cloud, $C_a$ is the center of rotation in CH1903+ referential frame and $S$ is a shift to have a precise
   point cloud rendering. However, the store point cloud is ofter $X_{CH1903}-S$, so the above transformation become
   \begin{equation}
       X_{S}  = s R_a ( X_{trans} - C_a ) \Leftrightarrow X_{trans} = \frac{1}{s} R_a^T ( X_{S} + C_a )
   \end{equation}
   and we only need to take $S$ into account for exportation of true CH1903 coordinates (and not for the projection part).
   Moreover, if a rigid transformation is applied to the point cloud generated by openMVG, 
   $X_{trans}$ and $X_{omvg}$ are related by the following relation :
   \begin{equation}
       X_{trans} = R_2 X_{omvg} + \t_2 \Leftrightarrow X_{omvg} = R_2^T (X_{trans} - \t_2).
   \end{equation}
   where $R_2$ is a rotation matrix and $\t_2$ is a translation. Generally, no transformation is applied on the point
   cloud, so if not provided, the default value of $R_2$ and $\t_2$ are $I_3$ and $0$ respectively. 
   Finally, the coordinates $X_r$ in the pose referential frame of the 3D point $X_{omvg}$ is given by
   \begin{equation}
       X_r = R_r (X_{omvg}-C_r).
   \end{equation}
   where $(R_r, C_r)$ is the pose of the panorama in openMVG referential frame. 
   Note that $R_r$ is a rotation matrix and $C_r$ is the center of the eyesis in openMVG referential frame. 
   The final application we need to have the full transformation is the relation between a point $X_r$ in the pose referential 
   frame to $X_{wgl}$ in webGL coordinates frame, which is simply given by
   \begin{equation}
       X_{wgl} = R_x(\pi) X_r
   \end{equation}
   where $R_x(\pi)$ is simply a rotation of angle $\pi$ around the $x$-axis. Combining those relations together, the transformation 
   from the shifted aligned referential frame to the WebGL coordinate frame is then 
   \begin{equation}
       \begin{aligned}
           & X_{wgl} & = & \frac{1}{s} R_x(\pi) R_r R_2^T R_a^T X_S + \frac{1}{s} R_x(\pi) R_r R_2^T C_a \\
            &&&       -R_x(\pi) R_r R_2^T \t_2 - R_x(\pi) R_r C_r.
       \end{aligned}
   \end{equation}  
   Let us define $\overline X $ as the 3D you need for projection onto panorama, and $\tilde X$ the 3D point you need 
   for measurements. Then 
   \begin{equation}
        \begin{aligned}
        \overline X & = && R_x(\pi) X_{wgl} \\
        \tilde X & = && s X_{wgl}
        \end{aligned}
   \end{equation}
   which is equivalent to 
   \begin{equation}
      \label{x-projected}
        \begin{aligned}
        \overline X = X_r & = && \frac{1}{s} R_r R_2^T R_a^T X_S + \frac{1}{s} R_r R_2^T C_a -R_r R_2^T \t_2 - R_r C_r. \\
        \tilde X & = && R_x(\pi) R_r R_2^T R_a^T X_S + R_x(\pi) R_r R_2^T C_a \\
            &&&       -s R_x(\pi) R_r R_2^T \t_2 - s R_x(\pi) R_r C_r.
        \end{aligned}
   \end{equation}
   \begin{paragraph}{Remark}
      The relations in \eqref{x-projected} could be simplified. Indeed, generally, $R_2 = I_3$ and $t_2 = 0$, which is
      the case when the point cloud generated by openMVG is not modified by a post-processing. So, if the additionnal
      rigid transformation of openMVG point cloud is not provided, we assume that $R_2 = I_3$ et $t_2 = 0$ in ply2bin.
      Moreover, if the point cloud is not aligned, we made the assumption that $s=1.0$, $R_a = I_3,$ and $C_a = S = 0$, 
      which give the munch simpler relations $X_{CH1903} = X_{omvg}$ and $X_r = R_r (X_{omvg}-C_r)$.
      Hence, if no alignement transformation and / or no additional rigid transformation are not provided, the ply2bin would
      still work. Indeed, if an optionnal transformation is not given, ply2bin assumes that the corresponding transformation
      is $(I_3, 0)$.
   \end{paragraph}
   \\
   \\
   Then, to obtain the coordinate in local sensor coordinates, you only need to apply the pose $(R_c, C_c)$ of the
   channel $c$ to a point $X_r$ in the pose referential coordinate frame. This is given by the following application
   \begin{equation}
       X_c = R_c (X_r - C_c).
   \end{equation}
   Denoting by $K_c$ the camera matrix, $P^i$ the i-nth coordinate of a point $P$, 
   the projection of the point $X_r$ in pixels coordinate frame of channel $c$ is given by
   \begin{equation}
        X_{pix}^i = (K_c X_c)^i / X_{c}^3 \qquad i=1,2.
   \end{equation}
   which is equivalent to 
   \begin{equation}
        X_{pix}^i = ( K_c R_c X_r - K_c R_c C_c )^i / ( K_c R_c X_r - K_c R_c C_c )^3, \qquad i=1,2.
   \end{equation}
   
 \section*{Usage}
 To see the general usage of the software, in a terminal, enter
\begin{verbatim}
 ply2bin --help
\end{verbatim}
   which would display the following information
 \begin{verbatim}
Usage: ./ply2bin
[-p|--pointCloud]  pose cloud in ply format
[-f|--poseFile]    pose file
[-m|--macAddress]  camera mac adress
[-d|--mountPoint]  mount point 
[-o|--output]      output directory
        
Optionnal arguments 
[-a|--align]       alignment transformation
[-s|--scale]       scale factor file to have metric scale
[-t|--addTrans]    additional transformation 
                  (rigid transformation of openMVG point cloud)
[-j|--useJson]     export point cloud in json file or binary file. 
                   Default is binary
[-i|--pano]        complete path of the eqr panorama associated to pose 
                   file, for graphical export of projection
[-x|--sx]          x-coordinate shift to get true aligned coordinates
[-y|--sy]          y-coordinate shift to get true aligned coordinates
[-z|--sz]          z-coordinate shift to get true aligned coordinates
 \end{verbatim}
   For a more detailed usage of ply2bin, we refer us to the wiki page of ply2bin https://github.com/FoxelSA/ply2bin/wiki.
    
\section*{Conclusion}
  The sofware is perfectly working with JSON output files. During the projection step, a Z-buffering method is used to
  deal with occlusions. Concerning the binary output, it is working but actually, no
  validation tests are made with this ouput. Indeed, a new output file format will soon be on the road. The key idea of the
  new file format is the following :
  \begin{enumerate}
      \item We will have a binary file containing all the 3D points in CH1903 referential frame.
      \item for each pose, we store the indices of the 3D point that are seen in this pose, as the transformation
            from CH1903+ to local coordinate frame.
      \item We will make a query on the server in order to have the 3D coordinates of the pixel point seen in the panorama.
  \end{enumerate}




\end{document}